{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuCKZ6qE9Ql+e0FDup2aot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Light896cart/CV/blob/main/CV/Y/YOLOv1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DIHG4k14bsGq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import cv2\n",
        "import math\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_printoptions(precision=5, sci_mode=False)"
      ],
      "metadata": {
        "id": "XjXpQB3xDCUI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataFurcts(Dataset):\n",
        "  def __init__(self,path,transform):\n",
        "    self.path = path\n",
        "    self.transform = transform\n",
        "    self.size_img = (448,448)\n",
        "\n",
        "    xml_files = [xml_files for xml_files in os.listdir(path) if xml_files.endswith('.xml')]\n",
        "    self.dataset = list(self._XML_data(xml_files,path))  # Изменено на список\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    sample = self.dataset[idx]['filename']\n",
        "    img = Image.open(f'{self.path}/{sample}').convert('RGB')\n",
        "\n",
        "    original_size = img.size\n",
        "\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "\n",
        "\n",
        "    # Получаем размеры изображения для нормализации\n",
        "    width, height = img.shape[1:3]\n",
        "\n",
        "    # Нормализуем координаты\n",
        "    bndbox = self.dataset[idx]['bndbox']\n",
        "\n",
        "\n",
        "    original_bbox = torch.tensor([bndbox['xmin'],bndbox['ymin'],bndbox['xmax'],bndbox['ymax']])\n",
        "    new_bbox = self.resize_bbox(original_bbox,original_size)\n",
        "\n",
        "    x = torch.floor((new_bbox['xmin'] + new_bbox['xmax']) / 2 / 64).long()\n",
        "    y = torch.floor((new_bbox['ymin'] + new_bbox['ymax']) / 2 / 64).long()\n",
        "\n",
        "    normalized_x = (x % 48) / 48\n",
        "    normalized_y = (y % 48) / 48\n",
        "\n",
        "    width_norm = new_bbox['xmax'] - new_bbox['xmin']\n",
        "    height_norm = new_bbox['ymax'] - new_bbox['ymin']\n",
        "\n",
        "    cells = torch.zeros(49)\n",
        "    index = x * 7 + y\n",
        "\n",
        "    # Проверяем выход за пределы\n",
        "    if index < 49:\n",
        "        cells[index] = 1\n",
        "\n",
        "    normalization = {\n",
        "        'x': normalized_x,\n",
        "        'y': normalized_y,\n",
        "        'width': width_norm,\n",
        "        'height': height_norm,\n",
        "\n",
        "    }\n",
        "    reg = torch.stack(list(normalization.values()), dim=0).view(-1,4)\n",
        "    # Округление до 4 знаков после запятой\n",
        "    rounded_tensor = torch.round(reg * 100000) / 100000\n",
        "    return img, new_bbox, reg,cells\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def resize_bbox(self,bbox, original_size):\n",
        "    original_width, original_height = original_size\n",
        "    new_width, new_height = self.size_img\n",
        "\n",
        "    scale_x = new_width / original_width\n",
        "    scale_y = new_height / original_height\n",
        "\n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "\n",
        "    bndbox_disclosed = {\n",
        "        'xmin': x_min * scale_x,\n",
        "        'ymin': y_min * scale_y,\n",
        "        'xmax': x_max * scale_x,\n",
        "        'ymax': y_max * scale_y\n",
        "    }\n",
        "\n",
        "    return bndbox_disclosed\n",
        "\n",
        "  def _XML_data(self, xml_files, path):\n",
        "    for file in xml_files:\n",
        "        try:\n",
        "            # Загрузка и парсинг XML файла\n",
        "            tree = ET.parse(os.path.join(path, file))\n",
        "            root = tree.getroot()\n",
        "            # Извлечение данных\n",
        "            filename = root.find('filename').text\n",
        "\n",
        "            # Извлечение координат из bndbox\n",
        "            bndbox = root.find('./object/bndbox')\n",
        "            if bndbox is None:\n",
        "                continue  # Переход к следующему файлу, если bndbox отсутствует\n",
        "\n",
        "            xmin = float(bndbox.find('xmin').text)\n",
        "            ymin = float(bndbox.find('ymin').text)\n",
        "            xmax = float(bndbox.find('xmax').text)\n",
        "            ymax = float(bndbox.find('ymax').text)\n",
        "\n",
        "\n",
        "\n",
        "            yield {'filename': filename, 'bndbox': {'xmin':torch.tensor(xmin), 'ymin': torch.tensor(ymin), 'xmax': torch.tensor(xmax), 'ymax': torch.tensor(ymax)}}\n",
        "        except Exception as e:\n",
        "                print(f\"Ошибка {file}: {e}\")"
      ],
      "metadata": {
        "id": "XLkh870KDLZn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "            transforms.ToTensor(),  # Преобразует изображение в тензор\n",
        "            transforms.Resize((448,448)),\n",
        "            ])"
      ],
      "metadata": {
        "id": "jIJdh5PBDL9g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/fructs/train_zip/train'\n",
        "daset = DataFurcts(path,transform)\n",
        "data_train = DataLoader(daset,shuffle=True,batch_size=8)"
      ],
      "metadata": {
        "id": "BMTlteqsDL0p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLODetection(nn.Module):\n",
        "    def __init__(self, input_channels, S, C, B, batch_size):\n",
        "        super(YOLODetection, self).__init__()\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.S = S\n",
        "        self.C = C\n",
        "\n",
        "        self.backbone = nn.Sequential(\n",
        "            self._make_layer(input_channels, 64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            self._make_layer(64, 192, kernel_size=3, padding=1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            self._make_segment_3(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            self._make_segment_4(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            self._make_segment_5(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=50176, out_features=4096),\n",
        "        )\n",
        "        self.reg = nn.Linear(in_features=4096, out_features=4)\n",
        "\n",
        "        self.clasific = nn.Linear(in_features=4096, out_features=49)\n",
        "\n",
        "\n",
        "\n",
        "        # self._initialize_weights()\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "        layers = [\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "            nn.LeakyReLU()\n",
        "        ]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_segment_3(self):\n",
        "        return nn.Sequential(\n",
        "            self._make_layer(192, 128, 1),\n",
        "            self._make_layer(128, 256, 3),\n",
        "            self._make_layer(256, 256, 1),\n",
        "            self._make_layer(256, 512, 3, padding=2)\n",
        "        )\n",
        "\n",
        "    def _make_segment_4(self):\n",
        "      layers = nn.ModuleList()\n",
        "\n",
        "      for _ in range(4):\n",
        "          layers.append(self._make_layer(512, 256, kernel_size=1, padding=0))\n",
        "          layers.append(self._make_layer(256, 512, kernel_size=3, padding=0))\n",
        "\n",
        "      layers.append(self._make_layer(512, 512, 1,padding=2))\n",
        "      layers.append(self._make_layer(512, 1024, 3,padding=3))\n",
        "\n",
        "      return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_segment_5(self):\n",
        "      layers = nn.ModuleList()\n",
        "\n",
        "      for _ in range(2):\n",
        "        layers.append(self._make_layer(1024, 512, kernel_size=1))\n",
        "        layers.append(self._make_layer(512, 1024, kernel_size=1))\n",
        "\n",
        "      layers.append(self._make_layer(1024, 1024, kernel_size=3,padding=1))\n",
        "      layers.append(self._make_layer(1024, 1024, kernel_size=3,stride=2,padding=1))\n",
        "      return nn.Sequential(*layers)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "      for m in self.modules():\n",
        "          if isinstance(m, nn.Conv2d):\n",
        "              nn.init.normal_(m.weight, mean=0.0, std=0.05)  # Инициализация весов по нормальному распределению\n",
        "              if m.bias is not None:\n",
        "                  nn.init.zeros_(m.bias)\n",
        "          elif isinstance(m, nn.Linear):\n",
        "              nn.init.normal_(m.weight, mean=0.0, std=0.05)  # Инициализация весов по нормальному распределению\n",
        "              nn.init.zeros_(m.bias)\n",
        "\n",
        "\n",
        "    # def _transform(self,tenz):\n",
        "    #   return tenz.view(self.batch_size,5)\n",
        "\n",
        "    def detection(self, tensor):\n",
        "      # Получаем размеры батча и количество ячеек\n",
        "      batch_size = tensor.size(0)\n",
        "      num_cells = tensor.size(1)\n",
        "\n",
        "      # Извлекаем уверенность и координаты ячеек\n",
        "      confidence = tensor[:, :, 0]  # уверенность\n",
        "      x_cell = tensor[:, :, 1]  # координаты в ячейке x\n",
        "      y_cell = tensor[:, :, 2]  # координаты в ячейке y\n",
        "      width_cell = tensor[:, :, 3]  # ширина\n",
        "      height_cell = tensor[:, :, 4]  # высота\n",
        "\n",
        "      # Преобразование x и y из ячейки в координаты изображения\n",
        "      # Пропорциональное распределение по сетке\n",
        "      grid_x = (x_cell + (torch.arange(num_cells).unsqueeze(0) % 7).float()) * (448 / 7)\n",
        "      grid_y = (y_cell + (torch.arange(num_cells).unsqueeze(0) // 7).float()) * (448 / 7)\n",
        "\n",
        "      xmin = grid_x - (width_cell / 2)\n",
        "      ymin = grid_y - (height_cell / 2)\n",
        "      xmax = grid_x + (width_cell / 2)\n",
        "      ymax = grid_y + (height_cell / 2)\n",
        "\n",
        "      # Объединяем тензоры\n",
        "      output_tensor = torch.cat((confidence.unsqueeze(1), xmin.unsqueeze(1), ymin.unsqueeze(1), xmax.unsqueeze(1), ymax.unsqueeze(1)), dim=1).permute(0, 2, 1)\n",
        "      return output_tensor\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        reg = self.reg(x)\n",
        "        reg_1_2 = torch.sigmoid(self.reg(x)[:, :2])\n",
        "\n",
        "        reg_3_4 = self.reg(x)[:, 2:]\n",
        "        reg = torch.cat((reg_1_2, reg_3_4), dim=1)\n",
        "        clasific = self.clasific(x)\n",
        "        return reg, clasific"
      ],
      "metadata": {
        "id": "sT5saqQlDTSx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Первое, проверьте доступность GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = YOLODetection(input_channels=3,S=7,B=1,C=0,batch_size=1).to(device)"
      ],
      "metadata": {
        "id": "v3Z1RSuBDTQb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdUDmItSDTJP",
        "outputId": "9dc4660f-4c3c-4e49-e502-f4116acf26f8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLODetection(\n",
            "  (backbone): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
            "      (1): LeakyReLU(negative_slope=0.01)\n",
            "    )\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): Sequential(\n",
            "      (0): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.01)\n",
            "    )\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "    )\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (4): Sequential(\n",
            "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (5): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (6): Sequential(\n",
            "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (7): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (8): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (9): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "    )\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (4): Sequential(\n",
            "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "      (5): Sequential(\n",
            "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (1): LeakyReLU(negative_slope=0.01)\n",
            "      )\n",
            "    )\n",
            "    (9): Flatten(start_dim=1, end_dim=-1)\n",
            "    (10): Linear(in_features=50176, out_features=4096, bias=True)\n",
            "  )\n",
            "  (reg): Linear(in_features=4096, out_features=4, bias=True)\n",
            "  (clasific): Linear(in_features=4096, out_features=49, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_mse_yolos(prediction_S, target_S,prediction_reg,target_reg,lamda_coord, lamda_noobj):\n",
        "  target_index_x,target_index_y = target_S.nonzero(as_tuple=True)\n",
        "  target_index_null_x,target_index_null_y = (target_S == 0).nonzero(as_tuple=True)\n",
        "\n",
        "  # print(f'PREDICTION {target_reg[:,0]}')\n",
        "  x = (prediction_reg[:,0] - target_reg[:,0])**2\n",
        "  y = (prediction_reg[:,1] - target_reg[:,1])**2\n",
        "\n",
        "\n",
        "\n",
        "  local_one = lamda_coord * (x + y)[target_index_x]\n",
        "\n",
        "\n",
        "  width = (torch.sqrt(prediction_reg[:,2]) - torch.sqrt(target_reg[:,2]))**2\n",
        "  height = (torch.sqrt(prediction_reg[:,3]) - torch.sqrt(target_reg[:,3]))**2\n",
        "  local_two = lamda_coord * (width + height)[target_index_x]\n",
        "\n",
        "  C = (prediction_S - target_S) ** 2\n",
        "  confidence_one = C[target_index_x]\n",
        "  confidence_two = lamda_noobj * (C[target_index_null_x])\n",
        "\n",
        "  loss = torch.mean(local_one) + torch.mean(local_two) + torch.mean(confidence_one) + torch.mean(confidence_two)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "p-02bByob5gn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# criterion_clas = nn.MSE()\n",
        "optimizer = optim.Adam(model.clasific.parameters(),lr=1e-2)"
      ],
      "metadata": {
        "id": "QRqA0RL4D_NR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lamda_coord = 5\n",
        "lamda_noobj = 0.5\n",
        "\n",
        "model.train()\n",
        "for _ in range(50):\n",
        "    for img, _, label_reg, label_clas in data_train:\n",
        "      # Обнуление градиентов\n",
        "        optimizer.zero_grad()\n",
        "        img = img.to(device)\n",
        "        label_reg = label_reg.to(device).squeeze(1)\n",
        "        label_clas = label_clas.to(device)\n",
        "        output_reg, output_clas = model(img)\n",
        "        loss = loss_mse_yolos(output_clas,label_clas,output_reg,label_reg,lamda_coord,lamda_noobj)\n",
        "        # loss = loss_mse_yolo(output_clas,label_clas)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4zr-Pn5nEAJP",
        "outputId": "287442c0-6651-4e5b-fa25-df03f7a7f246"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2924.11060, grad_fn=<AddBackward0>)\n",
            "tensor(2380.58325, grad_fn=<AddBackward0>)\n",
            "tensor(2597.07031, grad_fn=<AddBackward0>)\n",
            "tensor(2642.97241, grad_fn=<AddBackward0>)\n",
            "tensor(2699.28516, grad_fn=<AddBackward0>)\n",
            "tensor(3015.30811, grad_fn=<AddBackward0>)\n",
            "tensor(2190.00244, grad_fn=<AddBackward0>)\n",
            "tensor(2891.07520, grad_fn=<AddBackward0>)\n",
            "tensor(2803.61279, grad_fn=<AddBackward0>)\n",
            "tensor(3049.77026, grad_fn=<AddBackward0>)\n",
            "tensor(2718.31909, grad_fn=<AddBackward0>)\n",
            "tensor(2508.51733, grad_fn=<AddBackward0>)\n",
            "tensor(2904.29102, grad_fn=<AddBackward0>)\n",
            "tensor(2557.73169, grad_fn=<AddBackward0>)\n",
            "tensor(2692.32739, grad_fn=<AddBackward0>)\n",
            "tensor(2434.38745, grad_fn=<AddBackward0>)\n",
            "tensor(3061.08008, grad_fn=<AddBackward0>)\n",
            "tensor(3066.53760, grad_fn=<AddBackward0>)\n",
            "tensor(2729.12549, grad_fn=<AddBackward0>)\n",
            "tensor(1640.86096, grad_fn=<AddBackward0>)\n",
            "tensor(2720.44287, grad_fn=<AddBackward0>)\n",
            "tensor(2426.24561, grad_fn=<AddBackward0>)\n",
            "tensor(2851.08862, grad_fn=<AddBackward0>)\n",
            "tensor(2703.10620, grad_fn=<AddBackward0>)\n",
            "tensor(3110.93628, grad_fn=<AddBackward0>)\n",
            "tensor(2705.10474, grad_fn=<AddBackward0>)\n",
            "tensor(2757.43384, grad_fn=<AddBackward0>)\n",
            "tensor(2368.65991, grad_fn=<AddBackward0>)\n",
            "tensor(2709.52979, grad_fn=<AddBackward0>)\n",
            "tensor(2493.53320, grad_fn=<AddBackward0>)\n",
            "tensor(2889.86279, grad_fn=<AddBackward0>)\n",
            "tensor(2818.40381, grad_fn=<AddBackward0>)\n",
            "tensor(2700.57104, grad_fn=<AddBackward0>)\n",
            "tensor(2847.73706, grad_fn=<AddBackward0>)\n",
            "tensor(2605.29297, grad_fn=<AddBackward0>)\n",
            "tensor(2564.04565, grad_fn=<AddBackward0>)\n",
            "tensor(2782.08887, grad_fn=<AddBackward0>)\n",
            "tensor(2826.59717, grad_fn=<AddBackward0>)\n",
            "tensor(2287.25415, grad_fn=<AddBackward0>)\n",
            "tensor(2575.37720, grad_fn=<AddBackward0>)\n",
            "tensor(2725.08716, grad_fn=<AddBackward0>)\n",
            "tensor(2925.56812, grad_fn=<AddBackward0>)\n",
            "tensor(2701.99585, grad_fn=<AddBackward0>)\n",
            "tensor(2652.84351, grad_fn=<AddBackward0>)\n",
            "tensor(2829.18921, grad_fn=<AddBackward0>)\n",
            "tensor(2312.59082, grad_fn=<AddBackward0>)\n",
            "tensor(2378.28296, grad_fn=<AddBackward0>)\n",
            "tensor(2649.16333, grad_fn=<AddBackward0>)\n",
            "tensor(2877.53857, grad_fn=<AddBackward0>)\n",
            "tensor(3294.26953, grad_fn=<AddBackward0>)\n",
            "tensor(3158.93164, grad_fn=<AddBackward0>)\n",
            "tensor(2336.56543, grad_fn=<AddBackward0>)\n",
            "tensor(2544.72510, grad_fn=<AddBackward0>)\n",
            "tensor(2704.22388, grad_fn=<AddBackward0>)\n",
            "tensor(2128.56323, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-941b364a98a3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_mse_yolos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_clas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_clas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_reg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_reg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamda_coord\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamda_noobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# loss = loss_mse_yolo(output_clas,label_clas)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_mse_yolos(prediction_S, target_S,prediction_reg,target_reg,lamda_coord, lamda_noobj):\n",
        "  target_index_x,target_index_y = target_S.nonzero(as_tuple=True)\n",
        "  target_index_null_x,target_index_null_y = (target_S == 0).nonzero(as_tuple=True)\n",
        "  print(f'X {target_index_x}')\n",
        "  print(f'Y {target_index_y}')\n",
        "\n",
        "  print()\n",
        "\n",
        "  # print(f'PREDICTION {target_reg[:,0]}')\n",
        "  x = (prediction_reg[:,0] - target_reg[:,0])**2\n",
        "  y = (prediction_reg[:,1] - target_reg[:,1])**2\n",
        "\n",
        "\n",
        "\n",
        "  local_one = lamda_coord * (x + y)[target_index_x]\n",
        "\n",
        "\n",
        "  width = (torch.sqrt(prediction_reg[:,2]) - torch.sqrt(target_reg[:,2]))**2\n",
        "  height = (torch.sqrt(prediction_reg[:,3]) - torch.sqrt(target_reg[:,3]))**2\n",
        "  local_two = lamda_coord * (width + height)[target_index_x]\n",
        "\n",
        "  C = (prediction_S - target_S) ** 2\n",
        "  confidence_one = C[target_index_x]\n",
        "  confidence_two = lamda_noobj * (C[target_index_null_x])\n",
        "\n",
        "  print(f'local_one {local_one.shape}')\n",
        "  print(f'local_two {local_two.shape}')\n",
        "  print(f'confidence_one {confidence_one.shape}')\n",
        "  print(f'confidence_two {confidence_two.shape}')\n",
        "\n",
        "  loss = torch.mean(local_one) + torch.mean(local_two) + torch.mean(confidence_one) + torch.mean(confidence_two)\n",
        "  print(loss)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "J-9AwhBlGl6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Xe7-dvpAUKXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lamda_coord = 5\n",
        "lamda_noobj = 0.5\n",
        "\n",
        "prediction_S = torch.tensor([[1., 0.,0.,0.,0.],\n",
        "                             [1., 0.,0.,0.,0.],\n",
        "                             [1., 0.,0.,0.,0.]])\n",
        "\n",
        "target_S = torch.tensor([[1., 0.,1.,0.,0.],\n",
        "                         [1., 0.,0.,0.,0.],\n",
        "                         [1., 0.,0.,0.,0.]])\n",
        "\n",
        "label_reg = torch.tensor([[0.6, 0.2, 110, 220],[0.4, 0.5, 150, 180],[0.4, 0.5, 150, 180]])\n",
        "\n",
        "prediction_reg = torch.tensor([[0.4, 0.2, 110, 220],[0.6, 0.5, 150, 180],[0.4, 0.5, 150, 180]])\n",
        "\n",
        "print(prediction_S.shape)\n",
        "loss_mse_yolos(prediction_S,target_S,prediction_reg,label_reg,lamda_coord,lamda_noobj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uW9dhtcb-Z0",
        "outputId": "5c208711-1c1e-4baa-a46f-40db758ee790"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 5])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.27727)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e7kTlS3Ub_1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zq4hc33RDaSf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}